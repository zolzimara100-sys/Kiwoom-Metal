#!/usr/bin/env python3
"""
GPU Stress Test - Maximum GPU Utilization
PyTorch MPSë¥¼ ì‚¬ìš©í•˜ì—¬ GPU ì‚¬ìš©ë¥ ì„ ê·¹ëŒ€í™”í•˜ëŠ” í…ŒìŠ¤íŠ¸
"""

import torch
import numpy as np
import time
import duckdb
from pathlib import Path

def gpu_stress_test():
    """GPU ìµœëŒ€ ì‚¬ìš©ë¥  í…ŒìŠ¤íŠ¸"""

    # GPU ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print(f"âœ… Metal GPU (MPS) detected")
    else:
        print("âŒ GPU not available")
        return

    # DuckDB ì—°ê²°
    db_path = '/Users/juhyunhwang/kiwoom-metal/data/kiwoom.duckdb'
    print(f"ğŸ“Š Loading data from DuckDB...")

    conn = duckdb.connect(db_path, read_only=True)

    # ëª¨ë“  ì¢…ëª©ì˜ ë°ì´í„° ë¡œë“œ
    query = """
        SELECT
            stk_cd,
            dt,
            frgnr,
            orgn,
            indiv,
            cur_prc
        FROM read_parquet('/Users/juhyunhwang/kiwoom-metal/data/parquet/tb_stock_investor_daily.parquet')
        ORDER BY stk_cd, dt
    """

    df = conn.execute(query).df()
    conn.close()

    print(f"ğŸ“ˆ Loaded {len(df):,} rows")
    print(f"ğŸ“ˆ Total stocks: {df['stk_cd'].nunique()}")

    # GPUë¡œ ëŒ€ëŸ‰ ì´ë™í‰ê·  ê³„ì‚°
    ma_windows = [5, 10, 20, 30, 40, 50, 60, 90, 120]

    print(f"\nğŸ® Starting GPU intensive calculations...")
    print(f"   - Windows: {ma_windows}")
    print(f"   - Device: {device}")
    print(f"\nâ±ï¸  GPU ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•˜ì„¸ìš”!")
    print(f"   macOS: sudo powermetrics --samplers gpu_power -i 500")
    print(f"   ë˜ëŠ”: Activity Monitor > Window > GPU History\n")

    time.sleep(3)

    start_time = time.time()
    processed_count = 0

    # ì¢…ëª©ë³„ë¡œ GPU ê³„ì‚° ìˆ˜í–‰
    for stk_cd, group in df.groupby('stk_cd'):
        group = group.sort_values('dt')

        # ê° íˆ¬ìì ìœ í˜•ë³„ ì²˜ë¦¬
        for investor_col in ['frgnr', 'orgn', 'indiv']:
            data = group[investor_col].values

            if len(data) < 10:
                continue

            # GPUë¡œ ë°ì´í„° ì „ì†¡ (optimized with explicit dtype)
            tensor = torch.from_numpy(data).to(device=device, dtype=torch.float32)

            # ëª¨ë“  ìœˆë„ìš°ì— ëŒ€í•´ ì´ë™í‰ê·  ê³„ì‚° (GPU intensive!)
            for window in ma_windows:
                if len(data) >= window:
                    # GPU Convolution (optimized with explicit dtype)
                    kernel = torch.ones(window, device=device, dtype=torch.float32) / window
                    padded = torch.nn.functional.pad(
                        tensor.unsqueeze(0).unsqueeze(0),
                        (window-1, 0)
                    )
                    ma = torch.nn.functional.conv1d(
                        padded,
                        kernel.unsqueeze(0).unsqueeze(0)
                    ).squeeze()

                    # CPUë¡œ ê²°ê³¼ ì „ì†¡ (ë™ê¸°í™”)
                    result = ma.cpu().numpy()
                    processed_count += 1

        # ì§„í–‰ìƒí™© ì¶œë ¥
        if processed_count % 100 == 0:
            elapsed = time.time() - start_time
            rate = processed_count / elapsed if elapsed > 0 else 0
            print(f"ğŸ® Processed: {processed_count:,} calculations | "
                  f"Rate: {rate:.1f} calc/sec | "
                  f"Stock: {stk_cd}")

    elapsed = time.time() - start_time

    print(f"\nâœ… GPU Stress Test Complete!")
    print(f"   - Total calculations: {processed_count:,}")
    print(f"   - Time: {elapsed:.1f} seconds")
    print(f"   - Rate: {processed_count/elapsed:.1f} calculations/second")
    print(f"   - Device: {device}")

if __name__ == "__main__":
    gpu_stress_test()
